{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkuzeyerkoc21\u001b[0m (\u001b[33mkuzey\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lenovo\\Documents\\frozen_lake\\wandb\\run-20240502_202107-50iicad4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kuzey/frozen_lake_project/runs/50iicad4' target=\"_blank\">polar-deluge-2</a></strong> to <a href='https://wandb.ai/kuzey/frozen_lake_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kuzey/frozen_lake_project' target=\"_blank\">https://wandb.ai/kuzey/frozen_lake_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kuzey/frozen_lake_project/runs/50iicad4' target=\"_blank\">https://wandb.ai/kuzey/frozen_lake_project/runs/50iicad4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.007499463856220245\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.008080079220235348\n",
      "Accuracy: %99.19\n",
      "--------------------------\n",
      "Loss: 0.00786709412932396\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.009496374987065792\n",
      "Accuracy: %99.05\n",
      "--------------------------\n",
      "Loss: 0.00813205260783434\n",
      "Accuracy: %99.19\n",
      "--------------------------\n",
      "Loss: 0.007711069658398628\n",
      "Accuracy: %99.23\n",
      "--------------------------\n",
      "Loss: 0.009080247022211552\n",
      "Accuracy: %99.09\n",
      "--------------------------\n",
      "Loss: 0.007876492105424404\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.011484606191515923\n",
      "Accuracy: %98.85\n",
      "--------------------------\n",
      "Loss: 0.009405650198459625\n",
      "Accuracy: %99.06\n",
      "--------------------------\n",
      "Loss: 0.009291778318583965\n",
      "Accuracy: %99.07\n",
      "--------------------------\n",
      "Loss: 0.008229891769587994\n",
      "Accuracy: %99.18\n",
      "--------------------------\n",
      "Loss: 0.018297769129276276\n",
      "Accuracy: %98.17\n",
      "--------------------------\n",
      "Loss: 0.011634426191449165\n",
      "Accuracy: %98.84\n",
      "--------------------------\n",
      "Loss: 0.011808625422418118\n",
      "Accuracy: %98.82\n",
      "--------------------------\n",
      "Loss: 0.009686189703643322\n",
      "Accuracy: %99.03\n",
      "--------------------------\n",
      "Loss: 0.008498442359268665\n",
      "Accuracy: %99.15\n",
      "--------------------------\n",
      "Loss: 0.008686023764312267\n",
      "Accuracy: %99.13\n",
      "--------------------------\n",
      "Loss: 0.010552826337516308\n",
      "Accuracy: %98.94\n",
      "--------------------------\n",
      "Loss: 0.007831680588424206\n",
      "Accuracy: %99.22\n",
      "--------------------------\n",
      "Loss: 0.007211902178823948\n",
      "Accuracy: %99.28\n",
      "--------------------------\n",
      "Loss: 0.007110795471817255\n",
      "Accuracy: %99.29\n",
      "--------------------------\n",
      "Loss: 0.005843141116201878\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.006478828843683004\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.016464930027723312\n",
      "Accuracy: %98.35\n",
      "--------------------------\n",
      "Loss: 0.008007539436221123\n",
      "Accuracy: %99.20\n",
      "--------------------------\n",
      "Loss: 0.010567697696387768\n",
      "Accuracy: %98.94\n",
      "--------------------------\n",
      "Loss: 0.007887010462582111\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.007615162990987301\n",
      "Accuracy: %99.24\n",
      "--------------------------\n",
      "Loss: 0.011748948134481907\n",
      "Accuracy: %98.83\n",
      "--------------------------\n",
      "Loss: 0.006716487463563681\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.007632698398083448\n",
      "Accuracy: %99.24\n",
      "--------------------------\n",
      "Loss: 0.00702759250998497\n",
      "Accuracy: %99.30\n",
      "--------------------------\n",
      "Loss: 0.008278372697532177\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.007506704423576593\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.00973525084555149\n",
      "Accuracy: %99.03\n",
      "--------------------------\n",
      "Loss: 0.009135178290307522\n",
      "Accuracy: %99.09\n",
      "--------------------------\n",
      "Loss: 0.005536720156669617\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.006209563463926315\n",
      "Accuracy: %99.38\n",
      "--------------------------\n",
      "Loss: 0.011333226226270199\n",
      "Accuracy: %98.87\n",
      "--------------------------\n",
      "Loss: 0.01780121959745884\n",
      "Accuracy: %98.22\n",
      "--------------------------\n",
      "Loss: 0.012414761818945408\n",
      "Accuracy: %98.76\n",
      "--------------------------\n",
      "Loss: 0.008846822194755077\n",
      "Accuracy: %99.12\n",
      "--------------------------\n",
      "Loss: 0.007435687351971865\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.005825018510222435\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.009212376549839973\n",
      "Accuracy: %99.08\n",
      "--------------------------\n",
      "Loss: 0.016488684341311455\n",
      "Accuracy: %98.35\n",
      "--------------------------\n",
      "Loss: 0.011522077023983002\n",
      "Accuracy: %98.85\n",
      "--------------------------\n",
      "Loss: 0.00970518495887518\n",
      "Accuracy: %99.03\n",
      "--------------------------\n",
      "Loss: 0.010332765057682991\n",
      "Accuracy: %98.97\n",
      "--------------------------\n",
      "Loss: 0.009228488430380821\n",
      "Accuracy: %99.08\n",
      "--------------------------\n",
      "Loss: 0.009662261232733727\n",
      "Accuracy: %99.03\n",
      "--------------------------\n",
      "Loss: 0.005723986774682999\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.010182203724980354\n",
      "Accuracy: %98.98\n",
      "--------------------------\n",
      "Loss: 0.006913415156304836\n",
      "Accuracy: %99.31\n",
      "--------------------------\n",
      "Loss: 0.010939122177660465\n",
      "Accuracy: %98.91\n",
      "--------------------------\n",
      "Loss: 0.006047111935913563\n",
      "Accuracy: %99.40\n",
      "--------------------------\n",
      "Loss: 0.008346847258508205\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.009277266450226307\n",
      "Accuracy: %99.07\n",
      "--------------------------\n",
      "Loss: 0.014211330562829971\n",
      "Accuracy: %98.58\n",
      "--------------------------\n",
      "Loss: 0.007461055181920528\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.010010698810219765\n",
      "Accuracy: %99.00\n",
      "--------------------------\n",
      "Loss: 0.00897657498717308\n",
      "Accuracy: %99.10\n",
      "--------------------------\n",
      "Loss: 0.01237992849200964\n",
      "Accuracy: %98.76\n",
      "--------------------------\n",
      "Loss: 0.013449146412312984\n",
      "Accuracy: %98.66\n",
      "--------------------------\n",
      "Loss: 0.007739750202745199\n",
      "Accuracy: %99.23\n",
      "--------------------------\n",
      "Loss: 0.005781249608844519\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.010099463164806366\n",
      "Accuracy: %98.99\n",
      "--------------------------\n",
      "Loss: 0.015205730684101582\n",
      "Accuracy: %98.48\n",
      "--------------------------\n",
      "Loss: 0.014145574532449245\n",
      "Accuracy: %98.59\n",
      "--------------------------\n",
      "Loss: 0.009838027879595757\n",
      "Accuracy: %99.02\n",
      "--------------------------\n",
      "Loss: 0.009698774665594101\n",
      "Accuracy: %99.03\n",
      "--------------------------\n",
      "Loss: 0.005926412995904684\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.007735831663012505\n",
      "Accuracy: %99.23\n",
      "--------------------------\n",
      "Loss: 0.006839555222541094\n",
      "Accuracy: %99.32\n",
      "--------------------------\n",
      "Loss: 0.006698052864521742\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.014812200330197811\n",
      "Accuracy: %98.52\n",
      "--------------------------\n",
      "Loss: 0.011116443201899529\n",
      "Accuracy: %98.89\n",
      "--------------------------\n",
      "Loss: 0.0051230317912995815\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.011137916706502438\n",
      "Accuracy: %98.89\n",
      "--------------------------\n",
      "Loss: 0.008943285793066025\n",
      "Accuracy: %99.11\n",
      "--------------------------\n",
      "Loss: 0.007274460047483444\n",
      "Accuracy: %99.27\n",
      "--------------------------\n",
      "Loss: 0.00841413252055645\n",
      "Accuracy: %99.16\n",
      "--------------------------\n",
      "Loss: 0.010720602236688137\n",
      "Accuracy: %98.93\n",
      "--------------------------\n",
      "Loss: 0.006655482109636068\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.005373044405132532\n",
      "Accuracy: %99.46\n",
      "--------------------------\n",
      "Loss: 0.011223266832530499\n",
      "Accuracy: %98.88\n",
      "--------------------------\n",
      "Loss: 0.00822986476123333\n",
      "Accuracy: %99.18\n",
      "--------------------------\n",
      "Loss: 0.007549409754574299\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.0068666767328977585\n",
      "Accuracy: %99.31\n",
      "--------------------------\n",
      "Loss: 0.006007860414683819\n",
      "Accuracy: %99.40\n",
      "--------------------------\n",
      "Loss: 0.007180064916610718\n",
      "Accuracy: %99.28\n",
      "--------------------------\n",
      "Loss: 0.010622997768223286\n",
      "Accuracy: %98.94\n",
      "--------------------------\n",
      "Loss: 0.00448430934920907\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.007508886978030205\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.007146428804844618\n",
      "Accuracy: %99.29\n",
      "--------------------------\n",
      "Loss: 0.010253396816551685\n",
      "Accuracy: %98.97\n",
      "--------------------------\n",
      "Loss: 0.009124279953539371\n",
      "Accuracy: %99.09\n",
      "--------------------------\n",
      "Loss: 0.014686758629977703\n",
      "Accuracy: %98.53\n",
      "--------------------------\n",
      "Loss: 0.009302140213549137\n",
      "Accuracy: %99.07\n",
      "--------------------------\n",
      "Loss: 0.016037888824939728\n",
      "Accuracy: %98.40\n",
      "--------------------------\n",
      "Loss: 0.008610159158706665\n",
      "Accuracy: %99.14\n",
      "--------------------------\n",
      "Loss: 0.00760885514318943\n",
      "Accuracy: %99.24\n",
      "--------------------------\n",
      "Loss: 0.007717649452388287\n",
      "Accuracy: %99.23\n",
      "--------------------------\n",
      "Loss: 0.007130366284400225\n",
      "Accuracy: %99.29\n",
      "--------------------------\n",
      "Loss: 0.0073964535258710384\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.01232815720140934\n",
      "Accuracy: %98.77\n",
      "--------------------------\n",
      "Loss: 0.007917006500065327\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.010078836232423782\n",
      "Accuracy: %98.99\n",
      "--------------------------\n",
      "Loss: 0.007807542569935322\n",
      "Accuracy: %99.22\n",
      "--------------------------\n",
      "Loss: 0.007305589038878679\n",
      "Accuracy: %99.27\n",
      "--------------------------\n",
      "Loss: 0.009826764464378357\n",
      "Accuracy: %99.02\n",
      "--------------------------\n",
      "Loss: 0.014623233117163181\n",
      "Accuracy: %98.54\n",
      "--------------------------\n",
      "Loss: 0.006512769963592291\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.007879774086177349\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.006310966797173023\n",
      "Accuracy: %99.37\n",
      "--------------------------\n",
      "Loss: 0.006619478575885296\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.00747663201764226\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.00848747231066227\n",
      "Accuracy: %99.15\n",
      "--------------------------\n",
      "Loss: 0.00662542600184679\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.008027279749512672\n",
      "Accuracy: %99.20\n",
      "--------------------------\n",
      "Loss: 0.004805527627468109\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.005628946237266064\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.009039980359375477\n",
      "Accuracy: %99.10\n",
      "--------------------------\n",
      "Loss: 0.008698329329490662\n",
      "Accuracy: %99.13\n",
      "--------------------------\n",
      "Loss: 0.007094426546245813\n",
      "Accuracy: %99.29\n",
      "--------------------------\n",
      "Loss: 0.006807888392359018\n",
      "Accuracy: %99.32\n",
      "--------------------------\n",
      "Loss: 0.005013693124055862\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.015016430988907814\n",
      "Accuracy: %98.50\n",
      "--------------------------\n",
      "Loss: 0.006946275942027569\n",
      "Accuracy: %99.31\n",
      "--------------------------\n",
      "Loss: 0.005509903188794851\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.008382214233279228\n",
      "Accuracy: %99.16\n",
      "--------------------------\n",
      "Loss: 0.008647854439914227\n",
      "Accuracy: %99.14\n",
      "--------------------------\n",
      "Loss: 0.008580474182963371\n",
      "Accuracy: %99.14\n",
      "--------------------------\n",
      "Loss: 0.010609876364469528\n",
      "Accuracy: %98.94\n",
      "--------------------------\n",
      "Loss: 0.005920521914958954\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.009013529866933823\n",
      "Accuracy: %99.10\n",
      "--------------------------\n",
      "Loss: 0.012601056136190891\n",
      "Accuracy: %98.74\n",
      "--------------------------\n",
      "Loss: 0.007550788577646017\n",
      "Accuracy: %99.24\n",
      "--------------------------\n",
      "Loss: 0.006956029217690229\n",
      "Accuracy: %99.30\n",
      "--------------------------\n",
      "Loss: 0.006243092007935047\n",
      "Accuracy: %99.38\n",
      "--------------------------\n",
      "Loss: 0.0075197662226855755\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.0074370549991726875\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.008603199385106564\n",
      "Accuracy: %99.14\n",
      "--------------------------\n",
      "Loss: 0.006730183027684689\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.013637159951031208\n",
      "Accuracy: %98.64\n",
      "--------------------------\n",
      "Loss: 0.00850614532828331\n",
      "Accuracy: %99.15\n",
      "--------------------------\n",
      "Loss: 0.010760877281427383\n",
      "Accuracy: %98.92\n",
      "--------------------------\n",
      "Loss: 0.008501719683408737\n",
      "Accuracy: %99.15\n",
      "--------------------------\n",
      "Loss: 0.006390346679836512\n",
      "Accuracy: %99.36\n",
      "--------------------------\n",
      "Loss: 0.007438711356371641\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.007208629511296749\n",
      "Accuracy: %99.28\n",
      "--------------------------\n",
      "Loss: 0.007380018476396799\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.006658446043729782\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.004824744071811438\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.006165473256260157\n",
      "Accuracy: %99.38\n",
      "--------------------------\n",
      "Loss: 0.012462036684155464\n",
      "Accuracy: %98.75\n",
      "--------------------------\n",
      "Loss: 0.008243581280112267\n",
      "Accuracy: %99.18\n",
      "--------------------------\n",
      "Loss: 0.009943056851625443\n",
      "Accuracy: %99.01\n",
      "--------------------------\n",
      "Loss: 0.00790840107947588\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.006099562160670757\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.007498312275856733\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.007653987966477871\n",
      "Accuracy: %99.23\n",
      "--------------------------\n",
      "Loss: 0.0065101939253509045\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.009301971644163132\n",
      "Accuracy: %99.07\n",
      "--------------------------\n",
      "Loss: 0.008345108479261398\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.007113924715667963\n",
      "Accuracy: %99.29\n",
      "--------------------------\n",
      "Loss: 0.005050051491707563\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.006380966864526272\n",
      "Accuracy: %99.36\n",
      "--------------------------\n",
      "Loss: 0.007862929254770279\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.012391158379614353\n",
      "Accuracy: %98.76\n",
      "--------------------------\n",
      "Loss: 0.003995522856712341\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.005338553339242935\n",
      "Accuracy: %99.47\n",
      "--------------------------\n",
      "Loss: 0.006307361647486687\n",
      "Accuracy: %99.37\n",
      "--------------------------\n",
      "Loss: 0.006679615005850792\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.00829389225691557\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.010041139088571072\n",
      "Accuracy: %99.00\n",
      "--------------------------\n",
      "Loss: 0.008011461235582829\n",
      "Accuracy: %99.20\n",
      "--------------------------\n",
      "Loss: 0.008211118169128895\n",
      "Accuracy: %99.18\n",
      "--------------------------\n",
      "Loss: 0.014947479590773582\n",
      "Accuracy: %98.51\n",
      "--------------------------\n",
      "Loss: 0.006968213245272636\n",
      "Accuracy: %99.30\n",
      "--------------------------\n",
      "Loss: 0.0076471432112157345\n",
      "Accuracy: %99.24\n",
      "--------------------------\n",
      "Loss: 0.004784016869962215\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.010943948291242123\n",
      "Accuracy: %98.91\n",
      "--------------------------\n",
      "Loss: 0.006723799277096987\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.0062544504180550575\n",
      "Accuracy: %99.37\n",
      "--------------------------\n",
      "Loss: 0.007885696366429329\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.00703447125852108\n",
      "Accuracy: %99.30\n",
      "--------------------------\n",
      "Loss: 0.008108309470117092\n",
      "Accuracy: %99.19\n",
      "--------------------------\n",
      "Loss: 0.0072079929523169994\n",
      "Accuracy: %99.28\n",
      "--------------------------\n",
      "Loss: 0.006077041383832693\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.005923802498728037\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.005482713226228952\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.00576097471639514\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.011152850463986397\n",
      "Accuracy: %98.88\n",
      "--------------------------\n",
      "Loss: 0.010412327945232391\n",
      "Accuracy: %98.96\n",
      "--------------------------\n",
      "Loss: 0.011939617805182934\n",
      "Accuracy: %98.81\n",
      "--------------------------\n",
      "Loss: 0.009234407916665077\n",
      "Accuracy: %99.08\n",
      "--------------------------\n",
      "Loss: 0.007434955798089504\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.014990908093750477\n",
      "Accuracy: %98.50\n",
      "--------------------------\n",
      "Loss: 0.008153831586241722\n",
      "Accuracy: %99.18\n",
      "--------------------------\n",
      "Loss: 0.008555511012673378\n",
      "Accuracy: %99.14\n",
      "--------------------------\n",
      "Loss: 0.0075976913794875145\n",
      "Accuracy: %99.24\n",
      "--------------------------\n",
      "Loss: 0.009472125209867954\n",
      "Accuracy: %99.05\n",
      "--------------------------\n",
      "Loss: 0.0049969968385994434\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.01273396797478199\n",
      "Accuracy: %98.73\n",
      "--------------------------\n",
      "Loss: 0.007851459085941315\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.009161444380879402\n",
      "Accuracy: %99.08\n",
      "--------------------------\n",
      "Loss: 0.00787187460809946\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.007995343767106533\n",
      "Accuracy: %99.20\n",
      "--------------------------\n",
      "Loss: 0.007910754531621933\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.006646628491580486\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.010185481980443\n",
      "Accuracy: %98.98\n",
      "--------------------------\n",
      "Loss: 0.008228268474340439\n",
      "Accuracy: %99.18\n",
      "--------------------------\n",
      "Loss: 0.007423580624163151\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.006084421183913946\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.006787445861846209\n",
      "Accuracy: %99.32\n",
      "--------------------------\n",
      "Loss: 0.007870052009820938\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.005063984543085098\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.006822986528277397\n",
      "Accuracy: %99.32\n",
      "--------------------------\n",
      "Loss: 0.008268160745501518\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.008808488957583904\n",
      "Accuracy: %99.12\n",
      "--------------------------\n",
      "Loss: 0.004887748509645462\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.00978078506886959\n",
      "Accuracy: %99.02\n",
      "--------------------------\n",
      "Loss: 0.006129817571491003\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.007381716277450323\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.007023144047707319\n",
      "Accuracy: %99.30\n",
      "--------------------------\n",
      "Loss: 0.005519421771168709\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.006130243185907602\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.007283829618245363\n",
      "Accuracy: %99.27\n",
      "--------------------------\n",
      "Loss: 0.008346321992576122\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.005410908255726099\n",
      "Accuracy: %99.46\n",
      "--------------------------\n",
      "Loss: 0.008271526545286179\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.007527919020503759\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.013973205350339413\n",
      "Accuracy: %98.60\n",
      "--------------------------\n",
      "Loss: 0.00832294300198555\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.014507465995848179\n",
      "Accuracy: %98.55\n",
      "--------------------------\n",
      "Loss: 0.009840922430157661\n",
      "Accuracy: %99.02\n",
      "--------------------------\n",
      "Loss: 0.005595049820840359\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.005874086171388626\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.005753361154347658\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.006835573352873325\n",
      "Accuracy: %99.32\n",
      "--------------------------\n",
      "Loss: 0.004872210323810577\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.012776302173733711\n",
      "Accuracy: %98.72\n",
      "--------------------------\n",
      "Loss: 0.007300178986042738\n",
      "Accuracy: %99.27\n",
      "--------------------------\n",
      "Loss: 0.008196097798645496\n",
      "Accuracy: %99.18\n",
      "--------------------------\n",
      "Loss: 0.006591201759874821\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.00933357048779726\n",
      "Accuracy: %99.07\n",
      "--------------------------\n",
      "Loss: 0.007600549142807722\n",
      "Accuracy: %99.24\n",
      "--------------------------\n",
      "Loss: 0.006783789023756981\n",
      "Accuracy: %99.32\n",
      "--------------------------\n",
      "Loss: 0.006839933805167675\n",
      "Accuracy: %99.32\n",
      "--------------------------\n",
      "Loss: 0.00900469720363617\n",
      "Accuracy: %99.10\n",
      "--------------------------\n",
      "Loss: 0.007250661961734295\n",
      "Accuracy: %99.27\n",
      "--------------------------\n",
      "Loss: 0.008034135214984417\n",
      "Accuracy: %99.20\n",
      "--------------------------\n",
      "Loss: 0.007737769279628992\n",
      "Accuracy: %99.23\n",
      "--------------------------\n",
      "Loss: 0.017742060124874115\n",
      "Accuracy: %98.23\n",
      "--------------------------\n",
      "Loss: 0.007440720219165087\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.006727850530296564\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.005848237778991461\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.013449770398437977\n",
      "Accuracy: %98.66\n",
      "--------------------------\n",
      "Loss: 0.005900769494473934\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.013089957647025585\n",
      "Accuracy: %98.69\n",
      "--------------------------\n",
      "Loss: 0.006988021079450846\n",
      "Accuracy: %99.30\n",
      "--------------------------\n",
      "Loss: 0.00878201611340046\n",
      "Accuracy: %99.12\n",
      "--------------------------\n",
      "Loss: 0.0056543126702308655\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.015043492428958416\n",
      "Accuracy: %98.50\n",
      "--------------------------\n",
      "Loss: 0.004423967562615871\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.004750791471451521\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.006476806476712227\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.005845320411026478\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.009789157658815384\n",
      "Accuracy: %99.02\n",
      "--------------------------\n",
      "Loss: 0.00769825791940093\n",
      "Accuracy: %99.23\n",
      "--------------------------\n",
      "Loss: 0.005046257749199867\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.004591472912579775\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.004744481295347214\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.016031254082918167\n",
      "Accuracy: %98.40\n",
      "--------------------------\n",
      "Loss: 0.004827119875699282\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.006039027124643326\n",
      "Accuracy: %99.40\n",
      "--------------------------\n",
      "Loss: 0.007722661830484867\n",
      "Accuracy: %99.23\n",
      "--------------------------\n",
      "Loss: 0.0066148205660283566\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.008647320792078972\n",
      "Accuracy: %99.14\n",
      "--------------------------\n",
      "Loss: 0.007081968244165182\n",
      "Accuracy: %99.29\n",
      "--------------------------\n",
      "Loss: 0.006517129950225353\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.007444308139383793\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.006430682260543108\n",
      "Accuracy: %99.36\n",
      "--------------------------\n",
      "Loss: 0.007825160399079323\n",
      "Accuracy: %99.22\n",
      "--------------------------\n",
      "Loss: 0.008587024174630642\n",
      "Accuracy: %99.14\n",
      "--------------------------\n",
      "Loss: 0.012789592146873474\n",
      "Accuracy: %98.72\n",
      "--------------------------\n",
      "Loss: 0.006526208948343992\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.0062560406513512135\n",
      "Accuracy: %99.37\n",
      "--------------------------\n",
      "Loss: 0.00937067624181509\n",
      "Accuracy: %99.06\n",
      "--------------------------\n",
      "Loss: 0.005509332753717899\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.007178744301199913\n",
      "Accuracy: %99.28\n",
      "--------------------------\n",
      "Loss: 0.007177656516432762\n",
      "Accuracy: %99.28\n",
      "--------------------------\n",
      "Loss: 0.005186146125197411\n",
      "Accuracy: %99.48\n",
      "--------------------------\n",
      "Loss: 0.009166804142296314\n",
      "Accuracy: %99.08\n",
      "--------------------------\n",
      "Loss: 0.005458266474306583\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.005658387206494808\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.0056150262244045734\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.013493647798895836\n",
      "Accuracy: %98.65\n",
      "--------------------------\n",
      "Loss: 0.005882684141397476\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.005742365028709173\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.00908633228391409\n",
      "Accuracy: %99.09\n",
      "--------------------------\n",
      "Loss: 0.007539832033216953\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.006423297803848982\n",
      "Accuracy: %99.36\n",
      "--------------------------\n",
      "Loss: 0.008293518796563148\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.00624022725969553\n",
      "Accuracy: %99.38\n",
      "--------------------------\n",
      "Loss: 0.006570697762072086\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.008112148381769657\n",
      "Accuracy: %99.19\n",
      "--------------------------\n",
      "Loss: 0.00587935047224164\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.006282097660005093\n",
      "Accuracy: %99.37\n",
      "--------------------------\n",
      "Loss: 0.00650968961417675\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.0037405588664114475\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.009515511803328991\n",
      "Accuracy: %99.05\n",
      "--------------------------\n",
      "Loss: 0.006926398724317551\n",
      "Accuracy: %99.31\n",
      "--------------------------\n",
      "Loss: 0.012020659632980824\n",
      "Accuracy: %98.80\n",
      "--------------------------\n",
      "Loss: 0.009794473648071289\n",
      "Accuracy: %99.02\n",
      "--------------------------\n",
      "Loss: 0.006579007022082806\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.006930662784725428\n",
      "Accuracy: %99.31\n",
      "--------------------------\n",
      "Loss: 0.008616224862635136\n",
      "Accuracy: %99.14\n",
      "--------------------------\n",
      "Loss: 0.007168508134782314\n",
      "Accuracy: %99.28\n",
      "--------------------------\n",
      "Loss: 0.010319937951862812\n",
      "Accuracy: %98.97\n",
      "--------------------------\n",
      "Loss: 0.005610354244709015\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.0074616605415940285\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.007409394718706608\n",
      "Accuracy: %99.26\n",
      "--------------------------\n",
      "Loss: 0.012762274593114853\n",
      "Accuracy: %98.72\n",
      "--------------------------\n",
      "Loss: 0.014324161224067211\n",
      "Accuracy: %98.57\n",
      "--------------------------\n",
      "Loss: 0.003506670705974102\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.006340874824672937\n",
      "Accuracy: %99.37\n",
      "--------------------------\n",
      "Loss: 0.007044009864330292\n",
      "Accuracy: %99.30\n",
      "--------------------------\n",
      "Loss: 0.005698812659829855\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.00831677857786417\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.008082621730864048\n",
      "Accuracy: %99.19\n",
      "--------------------------\n",
      "Loss: 0.005815927404910326\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.004573697689920664\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.006363341119140387\n",
      "Accuracy: %99.36\n",
      "--------------------------\n",
      "Loss: 0.005137956235557795\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.007512402720749378\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.008095340803265572\n",
      "Accuracy: %99.19\n",
      "--------------------------\n",
      "Loss: 0.006090082693845034\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.010758375748991966\n",
      "Accuracy: %98.92\n",
      "--------------------------\n",
      "Loss: 0.006869661156088114\n",
      "Accuracy: %99.31\n",
      "--------------------------\n",
      "Loss: 0.008265812881290913\n",
      "Accuracy: %99.17\n",
      "--------------------------\n",
      "Loss: 0.006059361156076193\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.007533565629273653\n",
      "Accuracy: %99.25\n",
      "--------------------------\n",
      "Loss: 0.003803822910413146\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.007754072546958923\n",
      "Accuracy: %99.22\n",
      "--------------------------\n",
      "Loss: 0.006653354503214359\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.006690104957669973\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.005553619936108589\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.006542220711708069\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.0035932131577283144\n",
      "Accuracy: %99.64\n",
      "--------------------------\n",
      "Loss: 0.006922057364135981\n",
      "Accuracy: %99.31\n",
      "--------------------------\n",
      "Loss: 0.006199082359671593\n",
      "Accuracy: %99.38\n",
      "--------------------------\n",
      "Loss: 0.00792621448636055\n",
      "Accuracy: %99.21\n",
      "--------------------------\n",
      "Loss: 0.0065076653845608234\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.007293116766959429\n",
      "Accuracy: %99.27\n",
      "--------------------------\n",
      "Loss: 0.011446964927017689\n",
      "Accuracy: %98.86\n",
      "--------------------------\n",
      "Loss: 0.007130256853997707\n",
      "Accuracy: %99.29\n",
      "--------------------------\n",
      "Loss: 0.003669509431347251\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.010630669072270393\n",
      "Accuracy: %98.94\n",
      "--------------------------\n",
      "Loss: 0.0066511728800833225\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.004904118832200766\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.013122864998877048\n",
      "Accuracy: %98.69\n",
      "--------------------------\n",
      "Loss: 0.004963411949574947\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.006147054024040699\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.0030425782315433025\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.006369008217006922\n",
      "Accuracy: %99.36\n",
      "--------------------------\n",
      "Loss: 0.0035173010546714067\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.00727092707529664\n",
      "Accuracy: %99.27\n",
      "--------------------------\n",
      "Loss: 0.004776445217430592\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.0135189825668931\n",
      "Accuracy: %98.65\n",
      "--------------------------\n",
      "Loss: 0.004790797363966703\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.00479252589866519\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.004624524153769016\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.00399963092058897\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.005182296968996525\n",
      "Accuracy: %99.48\n",
      "--------------------------\n",
      "Loss: 0.013404762372374535\n",
      "Accuracy: %98.66\n",
      "--------------------------\n",
      "Loss: 0.0062736328691244125\n",
      "Accuracy: %99.37\n",
      "--------------------------\n",
      "Loss: 0.006191133055835962\n",
      "Accuracy: %99.38\n",
      "--------------------------\n",
      "Loss: 0.00506697129458189\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.006023752503097057\n",
      "Accuracy: %99.40\n",
      "--------------------------\n",
      "Loss: 0.0049058967269957066\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.0069687566719949245\n",
      "Accuracy: %99.30\n",
      "--------------------------\n",
      "Loss: 0.004898800048977137\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.006153331138193607\n",
      "Accuracy: %99.38\n",
      "--------------------------\n",
      "Loss: 0.005332957953214645\n",
      "Accuracy: %99.47\n",
      "--------------------------\n",
      "Loss: 0.006616838276386261\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.006041769403964281\n",
      "Accuracy: %99.40\n",
      "--------------------------\n",
      "Loss: 0.00863970909267664\n",
      "Accuracy: %99.14\n",
      "--------------------------\n",
      "Loss: 0.006119614001363516\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.00936749204993248\n",
      "Accuracy: %99.06\n",
      "--------------------------\n",
      "Loss: 0.0063119553960859776\n",
      "Accuracy: %99.37\n",
      "--------------------------\n",
      "Loss: 0.005658519454300404\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.00397208658978343\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.003978551831096411\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.004557850304991007\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.0071069663390517235\n",
      "Accuracy: %99.29\n",
      "--------------------------\n",
      "Loss: 0.007593365851789713\n",
      "Accuracy: %99.24\n",
      "--------------------------\n",
      "Loss: 0.006383804138749838\n",
      "Accuracy: %99.36\n",
      "--------------------------\n",
      "Loss: 0.012496130540966988\n",
      "Accuracy: %98.75\n",
      "--------------------------\n",
      "Loss: 0.0037519659381359816\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.005076157860457897\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.004729137290269136\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.004537324421107769\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.004354330711066723\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.004739431664347649\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.004335965495556593\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.005417156498879194\n",
      "Accuracy: %99.46\n",
      "--------------------------\n",
      "Loss: 0.004993002861738205\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.006265651900321245\n",
      "Accuracy: %99.37\n",
      "--------------------------\n",
      "Loss: 0.008684027008712292\n",
      "Accuracy: %99.13\n",
      "--------------------------\n",
      "Loss: 0.006753464229404926\n",
      "Accuracy: %99.32\n",
      "--------------------------\n",
      "Loss: 0.004251608159393072\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.005465662572532892\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.00351999350823462\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.006545981392264366\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.0072119152173399925\n",
      "Accuracy: %99.28\n",
      "--------------------------\n",
      "Loss: 0.0055469428189098835\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.01174930389970541\n",
      "Accuracy: %98.83\n",
      "--------------------------\n",
      "Loss: 0.006875337101519108\n",
      "Accuracy: %99.31\n",
      "--------------------------\n",
      "Loss: 0.005559218116104603\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.004119149874895811\n",
      "Accuracy: %99.59\n",
      "--------------------------\n",
      "Loss: 0.005526438821107149\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.0039743841625750065\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.004306889604777098\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.006376149132847786\n",
      "Accuracy: %99.36\n",
      "--------------------------\n",
      "Loss: 0.006681838072836399\n",
      "Accuracy: %99.33\n",
      "--------------------------\n",
      "Loss: 0.006592525634914637\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.004006525501608849\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.0032799881882965565\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.011710482649505138\n",
      "Accuracy: %98.83\n",
      "--------------------------\n",
      "Loss: 0.01365863811224699\n",
      "Accuracy: %98.63\n",
      "--------------------------\n",
      "Loss: 0.003883604658767581\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.006141188554465771\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.0053815776482224464\n",
      "Accuracy: %99.46\n",
      "--------------------------\n",
      "Loss: 0.002826688578352332\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.0035074620973318815\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.004470278974622488\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.003844392718747258\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.004587862174957991\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.005196698475629091\n",
      "Accuracy: %99.48\n",
      "--------------------------\n",
      "Loss: 0.011702955700457096\n",
      "Accuracy: %98.83\n",
      "--------------------------\n",
      "Loss: 0.011060680262744427\n",
      "Accuracy: %98.89\n",
      "--------------------------\n",
      "Loss: 0.005117612425237894\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.0066061378456652164\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.005326767452061176\n",
      "Accuracy: %99.47\n",
      "--------------------------\n",
      "Loss: 0.003977821208536625\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.006062356289476156\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.010795291513204575\n",
      "Accuracy: %98.92\n",
      "--------------------------\n",
      "Loss: 0.0049283974803984165\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.0036523640155792236\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.004361181519925594\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.002796404529362917\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.003815116360783577\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.003679070621728897\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.004286800045520067\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.005161243956536055\n",
      "Accuracy: %99.48\n",
      "--------------------------\n",
      "Loss: 0.010509313084185123\n",
      "Accuracy: %98.95\n",
      "--------------------------\n",
      "Loss: 0.0037785733584314585\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.004252755083143711\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.005843537859618664\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.0043840566650033\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.011789418756961823\n",
      "Accuracy: %98.82\n",
      "--------------------------\n",
      "Loss: 0.009986954741179943\n",
      "Accuracy: %99.00\n",
      "--------------------------\n",
      "Loss: 0.0036759397480636835\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.0031454891432076693\n",
      "Accuracy: %99.69\n",
      "--------------------------\n",
      "Loss: 0.005075737368315458\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.004180874675512314\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.005417018197476864\n",
      "Accuracy: %99.46\n",
      "--------------------------\n",
      "Loss: 0.005260126199573278\n",
      "Accuracy: %99.47\n",
      "--------------------------\n",
      "Loss: 0.011742277070879936\n",
      "Accuracy: %98.83\n",
      "--------------------------\n",
      "Loss: 0.0030240260530263186\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.004161174409091473\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.003940454218536615\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.004305909387767315\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.0045513492077589035\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.010484665632247925\n",
      "Accuracy: %98.95\n",
      "--------------------------\n",
      "Loss: 0.005877000279724598\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.012947343289852142\n",
      "Accuracy: %98.71\n",
      "--------------------------\n",
      "Loss: 0.003794935764744878\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.005571895744651556\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.012126125395298004\n",
      "Accuracy: %98.79\n",
      "--------------------------\n",
      "Loss: 0.010421019978821278\n",
      "Accuracy: %98.96\n",
      "--------------------------\n",
      "Loss: 0.004462835844606161\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.004504917189478874\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.004003609996289015\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.018668686971068382\n",
      "Accuracy: %98.13\n",
      "--------------------------\n",
      "Loss: 0.006582231726497412\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.0052244169637560844\n",
      "Accuracy: %99.48\n",
      "--------------------------\n",
      "Loss: 0.005078109912574291\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.011100550182163715\n",
      "Accuracy: %98.89\n",
      "--------------------------\n",
      "Loss: 0.002605320420116186\n",
      "Accuracy: %99.74\n",
      "--------------------------\n",
      "Loss: 0.0041509042493999004\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.01787339523434639\n",
      "Accuracy: %98.21\n",
      "--------------------------\n",
      "Loss: 0.005145049653947353\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.011205018498003483\n",
      "Accuracy: %98.88\n",
      "--------------------------\n",
      "Loss: 0.011318317614495754\n",
      "Accuracy: %98.87\n",
      "--------------------------\n",
      "Loss: 0.01120720710605383\n",
      "Accuracy: %98.88\n",
      "--------------------------\n",
      "Loss: 0.0032811604905873537\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.00476942490786314\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.00456697354093194\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.010717231780290604\n",
      "Accuracy: %98.93\n",
      "--------------------------\n",
      "Loss: 0.004515810403972864\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.0021489469800144434\n",
      "Accuracy: %99.79\n",
      "--------------------------\n",
      "Loss: 0.0039413319900631905\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.004200858063995838\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.0016530597349628806\n",
      "Accuracy: %99.83\n",
      "--------------------------\n",
      "Loss: 0.005669801030308008\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.0033465661108493805\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.010680794715881348\n",
      "Accuracy: %98.93\n",
      "--------------------------\n",
      "Loss: 0.0034733149223029613\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.011226406320929527\n",
      "Accuracy: %98.88\n",
      "--------------------------\n",
      "Loss: 0.004967480432242155\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.012168544344604015\n",
      "Accuracy: %98.78\n",
      "--------------------------\n",
      "Loss: 0.003176754107698798\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.011698724702000618\n",
      "Accuracy: %98.83\n",
      "--------------------------\n",
      "Loss: 0.005451194941997528\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.0030781137757003307\n",
      "Accuracy: %99.69\n",
      "--------------------------\n",
      "Loss: 0.0038536556530743837\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.011003286577761173\n",
      "Accuracy: %98.90\n",
      "--------------------------\n",
      "Loss: 0.018617942929267883\n",
      "Accuracy: %98.14\n",
      "--------------------------\n",
      "Loss: 0.012403585016727448\n",
      "Accuracy: %98.76\n",
      "--------------------------\n",
      "Loss: 0.010866906493902206\n",
      "Accuracy: %98.91\n",
      "--------------------------\n",
      "Loss: 0.0030195980798453093\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.002894159173592925\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.003869543084874749\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.004911887459456921\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.0026312931440770626\n",
      "Accuracy: %99.74\n",
      "--------------------------\n",
      "Loss: 0.005704759154468775\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.012080395594239235\n",
      "Accuracy: %98.79\n",
      "--------------------------\n",
      "Loss: 0.01183537021279335\n",
      "Accuracy: %98.82\n",
      "--------------------------\n",
      "Loss: 0.011375791393220425\n",
      "Accuracy: %98.86\n",
      "--------------------------\n",
      "Loss: 0.011046175844967365\n",
      "Accuracy: %98.90\n",
      "--------------------------\n",
      "Loss: 0.003973785787820816\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.005072164349257946\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.004620654974132776\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.010116539895534515\n",
      "Accuracy: %98.99\n",
      "--------------------------\n",
      "Loss: 0.0036430887412279844\n",
      "Accuracy: %99.64\n",
      "--------------------------\n",
      "Loss: 0.005437196232378483\n",
      "Accuracy: %99.46\n",
      "--------------------------\n",
      "Loss: 0.002505103824660182\n",
      "Accuracy: %99.75\n",
      "--------------------------\n",
      "Loss: 0.011983298696577549\n",
      "Accuracy: %98.80\n",
      "--------------------------\n",
      "Loss: 0.0060676513239741325\n",
      "Accuracy: %99.39\n",
      "--------------------------\n",
      "Loss: 0.0024464260786771774\n",
      "Accuracy: %99.76\n",
      "--------------------------\n",
      "Loss: 0.006821381859481335\n",
      "Accuracy: %99.32\n",
      "--------------------------\n",
      "Loss: 0.0031895628198981285\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.004456795752048492\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.004379783291369677\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.012548424303531647\n",
      "Accuracy: %98.75\n",
      "--------------------------\n",
      "Loss: 0.003727571340277791\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.0036475129891186953\n",
      "Accuracy: %99.64\n",
      "--------------------------\n",
      "Loss: 0.0028869155794382095\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.012561807408928871\n",
      "Accuracy: %98.74\n",
      "--------------------------\n",
      "Loss: 0.0030605881474912167\n",
      "Accuracy: %99.69\n",
      "--------------------------\n",
      "Loss: 0.011982033029198647\n",
      "Accuracy: %98.80\n",
      "--------------------------\n",
      "Loss: 0.003842171747237444\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.013029664754867554\n",
      "Accuracy: %98.70\n",
      "--------------------------\n",
      "Loss: 0.0035408399999141693\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.003206652356311679\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.0026557447854429483\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.0029564390424638987\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.004706753883510828\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.004421167075634003\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.002203048439696431\n",
      "Accuracy: %99.78\n",
      "--------------------------\n",
      "Loss: 0.004516256973147392\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.005703536793589592\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.004872216377407312\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.026803480461239815\n",
      "Accuracy: %97.32\n",
      "--------------------------\n",
      "Loss: 0.004930766299366951\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.004383001942187548\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.009334830567240715\n",
      "Accuracy: %99.07\n",
      "--------------------------\n",
      "Loss: 0.004418771713972092\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.004616674035787582\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.0033362400718033314\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.0031812575180083513\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.004682482220232487\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.003241261001676321\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.005610942374914885\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.003386478638276458\n",
      "Accuracy: %99.66\n",
      "--------------------------\n",
      "Loss: 0.010071363300085068\n",
      "Accuracy: %98.99\n",
      "--------------------------\n",
      "Loss: 0.002696115057915449\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.011190187186002731\n",
      "Accuracy: %98.88\n",
      "--------------------------\n",
      "Loss: 0.004371131770312786\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.0032708444632589817\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.004866030998528004\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.004301896318793297\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.003470335155725479\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.010352696292102337\n",
      "Accuracy: %98.96\n",
      "--------------------------\n",
      "Loss: 0.017924804240465164\n",
      "Accuracy: %98.21\n",
      "--------------------------\n",
      "Loss: 0.0047074537724256516\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.0037815161049365997\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.0022913184948265553\n",
      "Accuracy: %99.77\n",
      "--------------------------\n",
      "Loss: 0.003607704769819975\n",
      "Accuracy: %99.64\n",
      "--------------------------\n",
      "Loss: 0.011030079796910286\n",
      "Accuracy: %98.90\n",
      "--------------------------\n",
      "Loss: 0.00586311612278223\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.010598434135317802\n",
      "Accuracy: %98.94\n",
      "--------------------------\n",
      "Loss: 0.005589296575635672\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.0193752683699131\n",
      "Accuracy: %98.06\n",
      "--------------------------\n",
      "Loss: 0.00387417059391737\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.01093300711363554\n",
      "Accuracy: %98.91\n",
      "--------------------------\n",
      "Loss: 0.004909965675324202\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.011318812146782875\n",
      "Accuracy: %98.87\n",
      "--------------------------\n",
      "Loss: 0.004522308707237244\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.010967878624796867\n",
      "Accuracy: %98.90\n",
      "--------------------------\n",
      "Loss: 0.011445540003478527\n",
      "Accuracy: %98.86\n",
      "--------------------------\n",
      "Loss: 0.005005865357816219\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.0029175442177802324\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.02637116052210331\n",
      "Accuracy: %97.36\n",
      "--------------------------\n",
      "Loss: 0.003392695216462016\n",
      "Accuracy: %99.66\n",
      "--------------------------\n",
      "Loss: 0.018782710656523705\n",
      "Accuracy: %98.12\n",
      "--------------------------\n",
      "Loss: 0.012081241235136986\n",
      "Accuracy: %98.79\n",
      "--------------------------\n",
      "Loss: 0.0020686155185103416\n",
      "Accuracy: %99.79\n",
      "--------------------------\n",
      "Loss: 0.010378806851804256\n",
      "Accuracy: %98.96\n",
      "--------------------------\n",
      "Loss: 0.005075802095234394\n",
      "Accuracy: %99.49\n",
      "--------------------------\n",
      "Loss: 0.012135696597397327\n",
      "Accuracy: %98.79\n",
      "--------------------------\n",
      "Loss: 0.002798257628455758\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.009599330835044384\n",
      "Accuracy: %99.04\n",
      "--------------------------\n",
      "Loss: 0.003808654611930251\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.003940248861908913\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.003735593054443598\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.00990968570113182\n",
      "Accuracy: %99.01\n",
      "--------------------------\n",
      "Loss: 0.0018612045096233487\n",
      "Accuracy: %99.81\n",
      "--------------------------\n",
      "Loss: 0.0029336761217564344\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.005607301369309425\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.004977161064743996\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.011438152752816677\n",
      "Accuracy: %98.86\n",
      "--------------------------\n",
      "Loss: 0.013848911970853806\n",
      "Accuracy: %98.62\n",
      "--------------------------\n",
      "Loss: 0.004257465712726116\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.0036403986159712076\n",
      "Accuracy: %99.64\n",
      "--------------------------\n",
      "Loss: 0.004323720466345549\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.005833606235682964\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.0027065486647188663\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.004650891292840242\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.00245087593793869\n",
      "Accuracy: %99.75\n",
      "--------------------------\n",
      "Loss: 0.004412025213241577\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.005705048330128193\n",
      "Accuracy: %99.43\n",
      "--------------------------\n",
      "Loss: 0.004678014200180769\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.011145352385938168\n",
      "Accuracy: %98.89\n",
      "--------------------------\n",
      "Loss: 0.004433649592101574\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.0046565718948841095\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.0032052004244178534\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.003699180670082569\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.00471500214189291\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.004969761241227388\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.011993990279734135\n",
      "Accuracy: %98.80\n",
      "--------------------------\n",
      "Loss: 0.015830636024475098\n",
      "Accuracy: %98.42\n",
      "--------------------------\n",
      "Loss: 0.004514588974416256\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.005833651404827833\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.0034672454930841923\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.0037495989818125963\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.004311091732233763\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.010920915752649307\n",
      "Accuracy: %98.91\n",
      "--------------------------\n",
      "Loss: 0.0043936301954090595\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.004745875019580126\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.002988261403515935\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.010145086795091629\n",
      "Accuracy: %98.99\n",
      "--------------------------\n",
      "Loss: 0.010166733525693417\n",
      "Accuracy: %98.98\n",
      "--------------------------\n",
      "Loss: 0.004176575690507889\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.0048877643421292305\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.0030062757432460785\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.009366334415972233\n",
      "Accuracy: %99.06\n",
      "--------------------------\n",
      "Loss: 0.005783632397651672\n",
      "Accuracy: %99.42\n",
      "--------------------------\n",
      "Loss: 0.003433718578889966\n",
      "Accuracy: %99.66\n",
      "--------------------------\n",
      "Loss: 0.00874785240739584\n",
      "Accuracy: %99.13\n",
      "--------------------------\n",
      "Loss: 0.009938107803463936\n",
      "Accuracy: %99.01\n",
      "--------------------------\n",
      "Loss: 0.003679281799122691\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.009165765717625618\n",
      "Accuracy: %99.08\n",
      "--------------------------\n",
      "Loss: 0.002485894598066807\n",
      "Accuracy: %99.75\n",
      "--------------------------\n",
      "Loss: 0.011701783165335655\n",
      "Accuracy: %98.83\n",
      "--------------------------\n",
      "Loss: 0.010380812920629978\n",
      "Accuracy: %98.96\n",
      "--------------------------\n",
      "Loss: 0.004175764042884111\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.010665739886462688\n",
      "Accuracy: %98.93\n",
      "--------------------------\n",
      "Loss: 0.011551891453564167\n",
      "Accuracy: %98.84\n",
      "--------------------------\n",
      "Loss: 0.00595470517873764\n",
      "Accuracy: %99.40\n",
      "--------------------------\n",
      "Loss: 0.0036579384468495846\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.002740296069532633\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.017343057319521904\n",
      "Accuracy: %98.27\n",
      "--------------------------\n",
      "Loss: 0.0034974440932273865\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.003938745241612196\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.004560474306344986\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.004981286358088255\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.003710663877427578\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.0031901036854833364\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.011139036156237125\n",
      "Accuracy: %98.89\n",
      "--------------------------\n",
      "Loss: 0.0024115811102092266\n",
      "Accuracy: %99.76\n",
      "--------------------------\n",
      "Loss: 0.0041052429005503654\n",
      "Accuracy: %99.59\n",
      "--------------------------\n",
      "Loss: 0.010223356075584888\n",
      "Accuracy: %98.98\n",
      "--------------------------\n",
      "Loss: 0.0038311490789055824\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.004374423995614052\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.001942891045473516\n",
      "Accuracy: %99.81\n",
      "--------------------------\n",
      "Loss: 0.0045355623587965965\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.0016283864388242364\n",
      "Accuracy: %99.84\n",
      "--------------------------\n",
      "Loss: 0.004442757926881313\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.0033083749003708363\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.01691998355090618\n",
      "Accuracy: %98.31\n",
      "--------------------------\n",
      "Loss: 0.004410067107528448\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.004079972393810749\n",
      "Accuracy: %99.59\n",
      "--------------------------\n",
      "Loss: 0.0043406314216554165\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.01017401646822691\n",
      "Accuracy: %98.98\n",
      "--------------------------\n",
      "Loss: 0.004505605436861515\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.0047368742525577545\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.0029056768398731947\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.002790158847346902\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.010110956616699696\n",
      "Accuracy: %98.99\n",
      "--------------------------\n",
      "Loss: 0.003990778233855963\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.0037562032230198383\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.0047224778681993484\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.011063567362725735\n",
      "Accuracy: %98.89\n",
      "--------------------------\n",
      "Loss: 0.004715328570455313\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.010295085608959198\n",
      "Accuracy: %98.97\n",
      "--------------------------\n",
      "Loss: 0.004665863234549761\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.0028998968191444874\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.010859084315598011\n",
      "Accuracy: %98.91\n",
      "--------------------------\n",
      "Loss: 0.004742372781038284\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.0033329520374536514\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.006517565343528986\n",
      "Accuracy: %99.35\n",
      "--------------------------\n",
      "Loss: 0.004388417582958937\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.009317750111222267\n",
      "Accuracy: %99.07\n",
      "--------------------------\n",
      "Loss: 0.004795951768755913\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.0021843144204467535\n",
      "Accuracy: %99.78\n",
      "--------------------------\n",
      "Loss: 0.003105043200775981\n",
      "Accuracy: %99.69\n",
      "--------------------------\n",
      "Loss: 0.002671397291123867\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.005474486853927374\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.004837905056774616\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.0031746304593980312\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.0026003392413258553\n",
      "Accuracy: %99.74\n",
      "--------------------------\n",
      "Loss: 0.003242156468331814\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.004212702624499798\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.003322205040603876\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.003912689164280891\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.00418936088681221\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.003318146336823702\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.0028108570259064436\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.0059343199245631695\n",
      "Accuracy: %99.41\n",
      "--------------------------\n",
      "Loss: 0.005450801458209753\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.0052009886130690575\n",
      "Accuracy: %99.48\n",
      "--------------------------\n",
      "Loss: 0.003153609810397029\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.004242568742483854\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.004170035012066364\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.0031880394089967012\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.004177078604698181\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.003343380056321621\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.01188252680003643\n",
      "Accuracy: %98.81\n",
      "--------------------------\n",
      "Loss: 0.0044691176153719425\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.004941652528941631\n",
      "Accuracy: %99.51\n",
      "--------------------------\n",
      "Loss: 0.0021939340513199568\n",
      "Accuracy: %99.78\n",
      "--------------------------\n",
      "Loss: 0.00520578445866704\n",
      "Accuracy: %99.48\n",
      "--------------------------\n",
      "Loss: 0.0037758105900138617\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.006633994169533253\n",
      "Accuracy: %99.34\n",
      "--------------------------\n",
      "Loss: 0.0030063523445278406\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.005017874762415886\n",
      "Accuracy: %99.50\n",
      "--------------------------\n",
      "Loss: 0.010822812095284462\n",
      "Accuracy: %98.92\n",
      "--------------------------\n",
      "Loss: 0.005320888943970203\n",
      "Accuracy: %99.47\n",
      "--------------------------\n",
      "Loss: 0.003833877621218562\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.0031815345864742994\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.005452320910990238\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.018248483538627625\n",
      "Accuracy: %98.18\n",
      "--------------------------\n",
      "Loss: 0.0031270496547222137\n",
      "Accuracy: %99.69\n",
      "--------------------------\n",
      "Loss: 0.002674515824764967\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.0030509228818118572\n",
      "Accuracy: %99.69\n",
      "--------------------------\n",
      "Loss: 0.0029583717696368694\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.0038965665735304356\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.009978925809264183\n",
      "Accuracy: %99.00\n",
      "--------------------------\n",
      "Loss: 0.004450623411685228\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.010548647493124008\n",
      "Accuracy: %98.95\n",
      "--------------------------\n",
      "Loss: 0.0035935547202825546\n",
      "Accuracy: %99.64\n",
      "--------------------------\n",
      "Loss: 0.003846570383757353\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.0028276138473302126\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.011296535842120647\n",
      "Accuracy: %98.87\n",
      "--------------------------\n",
      "Loss: 0.004396391101181507\n",
      "Accuracy: %99.56\n",
      "--------------------------\n",
      "Loss: 0.002869154792279005\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.0037303734570741653\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.006210229825228453\n",
      "Accuracy: %99.38\n",
      "--------------------------\n",
      "Loss: 0.002939854981377721\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.01114151906222105\n",
      "Accuracy: %98.89\n",
      "--------------------------\n",
      "Loss: 0.003085046075284481\n",
      "Accuracy: %99.69\n",
      "--------------------------\n",
      "Loss: 0.011279027909040451\n",
      "Accuracy: %98.87\n",
      "--------------------------\n",
      "Loss: 0.003514460986480117\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.0017494576750323176\n",
      "Accuracy: %99.83\n",
      "--------------------------\n",
      "Loss: 0.01092864852398634\n",
      "Accuracy: %98.91\n",
      "--------------------------\n",
      "Loss: 0.003581190248951316\n",
      "Accuracy: %99.64\n",
      "--------------------------\n",
      "Loss: 0.0046141548082232475\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.0032620946876704693\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.00288029620423913\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.002959182485938072\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.00242325640283525\n",
      "Accuracy: %99.76\n",
      "--------------------------\n",
      "Loss: 0.003246408188715577\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.003189214738085866\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.0037516888696700335\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.005605161190032959\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.0026252607349306345\n",
      "Accuracy: %99.74\n",
      "--------------------------\n",
      "Loss: 0.004210832063108683\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.004814686253666878\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.0033296754118055105\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.009590521454811096\n",
      "Accuracy: %99.04\n",
      "--------------------------\n",
      "Loss: 0.0038589113391935825\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.002720775781199336\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.003208506153896451\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.002837874460965395\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.00470845028758049\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.004488463047891855\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.0021894595120102167\n",
      "Accuracy: %99.78\n",
      "--------------------------\n",
      "Loss: 0.004831783939152956\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.0029415700118988752\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.004824918694794178\n",
      "Accuracy: %99.52\n",
      "--------------------------\n",
      "Loss: 0.011624481528997421\n",
      "Accuracy: %98.84\n",
      "--------------------------\n",
      "Loss: 0.0045509375631809235\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.00538992416113615\n",
      "Accuracy: %99.46\n",
      "--------------------------\n",
      "Loss: 0.004561941139400005\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.0034420397132635117\n",
      "Accuracy: %99.66\n",
      "--------------------------\n",
      "Loss: 0.00554846553131938\n",
      "Accuracy: %99.45\n",
      "--------------------------\n",
      "Loss: 0.003314319998025894\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.003871217370033264\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.0039044776931405067\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.004317096900194883\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.01094698067754507\n",
      "Accuracy: %98.91\n",
      "--------------------------\n",
      "Loss: 0.0037262453697621822\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.0031332422513514757\n",
      "Accuracy: %99.69\n",
      "--------------------------\n",
      "Loss: 0.009988606907427311\n",
      "Accuracy: %99.00\n",
      "--------------------------\n",
      "Loss: 0.002906034467741847\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.004301106091588736\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.0026566232554614544\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.0032520031090825796\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.004546199459582567\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.005551592912524939\n",
      "Accuracy: %99.44\n",
      "--------------------------\n",
      "Loss: 0.004000699147582054\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.0033264756202697754\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.003833950264379382\n",
      "Accuracy: %99.62\n",
      "--------------------------\n",
      "Loss: 0.0017667361535131931\n",
      "Accuracy: %99.82\n",
      "--------------------------\n",
      "Loss: 0.00417776545509696\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.004225074779242277\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.004079013131558895\n",
      "Accuracy: %99.59\n",
      "--------------------------\n",
      "Loss: 0.00445786165073514\n",
      "Accuracy: %99.55\n",
      "--------------------------\n",
      "Loss: 0.0020048916339874268\n",
      "Accuracy: %99.80\n",
      "--------------------------\n",
      "Loss: 0.009991574101150036\n",
      "Accuracy: %99.00\n",
      "--------------------------\n",
      "Loss: 0.003511518007144332\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.008671987801790237\n",
      "Accuracy: %99.13\n",
      "--------------------------\n",
      "Loss: 0.004613972268998623\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.003716222010552883\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.0047272504307329655\n",
      "Accuracy: %99.53\n",
      "--------------------------\n",
      "Loss: 0.004011089447885752\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.0018988000229001045\n",
      "Accuracy: %99.81\n",
      "--------------------------\n",
      "Loss: 0.0019232525955885649\n",
      "Accuracy: %99.81\n",
      "--------------------------\n",
      "Loss: 0.0035373924765735865\n",
      "Accuracy: %99.65\n",
      "--------------------------\n",
      "Loss: 0.0034485813230276108\n",
      "Accuracy: %99.66\n",
      "--------------------------\n",
      "Loss: 0.004167230799794197\n",
      "Accuracy: %99.58\n",
      "--------------------------\n",
      "Loss: 0.003909351769834757\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.0028994320891797543\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.002497900277376175\n",
      "Accuracy: %99.75\n",
      "--------------------------\n",
      "Loss: 0.0038816474843770266\n",
      "Accuracy: %99.61\n",
      "--------------------------\n",
      "Loss: 0.0041168755851686\n",
      "Accuracy: %99.59\n",
      "--------------------------\n",
      "Loss: 0.00399416359141469\n",
      "Accuracy: %99.60\n",
      "--------------------------\n",
      "Loss: 0.004566110670566559\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.0032939761877059937\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.004330518655478954\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.010255463421344757\n",
      "Accuracy: %98.97\n",
      "--------------------------\n",
      "Loss: 0.003442897228524089\n",
      "Accuracy: %99.66\n",
      "--------------------------\n",
      "Loss: 0.0021705746185034513\n",
      "Accuracy: %99.78\n",
      "--------------------------\n",
      "Loss: 0.002757083624601364\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.0028202785179018974\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.004648155067116022\n",
      "Accuracy: %99.54\n",
      "--------------------------\n",
      "Loss: 0.0036076921969652176\n",
      "Accuracy: %99.64\n",
      "--------------------------\n",
      "Loss: 0.002521630609408021\n",
      "Accuracy: %99.75\n",
      "--------------------------\n",
      "Loss: 0.002832145895808935\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.003318199422210455\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.0028969438280910254\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.003429145785048604\n",
      "Accuracy: %99.66\n",
      "--------------------------\n",
      "Loss: 0.0018392077181488276\n",
      "Accuracy: %99.82\n",
      "--------------------------\n",
      "Loss: 0.0036030688788741827\n",
      "Accuracy: %99.64\n",
      "--------------------------\n",
      "Loss: 0.004303107503801584\n",
      "Accuracy: %99.57\n",
      "--------------------------\n",
      "Loss: 0.002568516880273819\n",
      "Accuracy: %99.74\n",
      "--------------------------\n",
      "Loss: 0.002711381297558546\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.0025116901379078627\n",
      "Accuracy: %99.75\n",
      "--------------------------\n",
      "Loss: 0.0030533538665622473\n",
      "Accuracy: %99.69\n",
      "--------------------------\n",
      "Loss: 0.0029236904811114073\n",
      "Accuracy: %99.71\n",
      "--------------------------\n",
      "Loss: 0.0036682160571217537\n",
      "Accuracy: %99.63\n",
      "--------------------------\n",
      "Loss: 0.0016052080318331718\n",
      "Accuracy: %99.84\n",
      "--------------------------\n",
      "Loss: 0.003395404201000929\n",
      "Accuracy: %99.66\n",
      "--------------------------\n",
      "Loss: 0.0018867860781028867\n",
      "Accuracy: %99.81\n",
      "--------------------------\n",
      "Loss: 0.0029535568319261074\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.00900654960423708\n",
      "Accuracy: %99.10\n",
      "--------------------------\n",
      "Loss: 0.002188197337090969\n",
      "Accuracy: %99.78\n",
      "--------------------------\n",
      "Loss: 0.003302086843177676\n",
      "Accuracy: %99.67\n",
      "--------------------------\n",
      "Loss: 0.0024318986106663942\n",
      "Accuracy: %99.76\n",
      "--------------------------\n",
      "Loss: 0.003164037363603711\n",
      "Accuracy: %99.68\n",
      "--------------------------\n",
      "Loss: 0.0028406716883182526\n",
      "Accuracy: %99.72\n",
      "--------------------------\n",
      "Loss: 0.002213046420365572\n",
      "Accuracy: %99.78\n",
      "--------------------------\n",
      "Loss: 0.0018573204288259149\n",
      "Accuracy: %99.81\n",
      "--------------------------\n",
      "Loss: 0.002205745317041874\n",
      "Accuracy: %99.78\n",
      "--------------------------\n",
      "Loss: 0.009042386896908283\n",
      "Accuracy: %99.10\n",
      "--------------------------\n",
      "Loss: 0.0019945327658206224\n",
      "Accuracy: %99.80\n",
      "--------------------------\n",
      "Loss: 0.002467542886734009\n",
      "Accuracy: %99.75\n",
      "--------------------------\n",
      "Loss: 0.000783053576014936\n",
      "Accuracy: %99.92\n",
      "--------------------------\n",
      "Loss: 0.001350217149592936\n",
      "Accuracy: %99.86\n",
      "--------------------------\n",
      "Loss: 0.009286033920943737\n",
      "Accuracy: %99.07\n",
      "--------------------------\n",
      "Loss: 0.0019648605957627296\n",
      "Accuracy: %99.80\n",
      "--------------------------\n",
      "Loss: 0.002663441002368927\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.001522171776741743\n",
      "Accuracy: %99.85\n",
      "--------------------------\n",
      "Loss: 0.0014682249166071415\n",
      "Accuracy: %99.85\n",
      "--------------------------\n",
      "Loss: 0.002425513230264187\n",
      "Accuracy: %99.76\n",
      "--------------------------\n",
      "Loss: 0.0013264281442388892\n",
      "Accuracy: %99.87\n",
      "--------------------------\n",
      "Loss: 0.0029501726385205984\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.0019563317764550447\n",
      "Accuracy: %99.80\n",
      "--------------------------\n",
      "Loss: 0.0005749881383962929\n",
      "Accuracy: %99.94\n",
      "--------------------------\n",
      "Loss: 0.001633243984542787\n",
      "Accuracy: %99.84\n",
      "--------------------------\n",
      "Loss: 0.0017037801444530487\n",
      "Accuracy: %99.83\n",
      "--------------------------\n",
      "Loss: 0.0017820807406678796\n",
      "Accuracy: %99.82\n",
      "--------------------------\n",
      "Loss: 0.0018163393251597881\n",
      "Accuracy: %99.82\n",
      "--------------------------\n",
      "Loss: 0.00112334790173918\n",
      "Accuracy: %99.89\n",
      "--------------------------\n",
      "Loss: 0.0009911988163366914\n",
      "Accuracy: %99.90\n",
      "--------------------------\n",
      "Loss: 0.009174413979053497\n",
      "Accuracy: %99.08\n",
      "--------------------------\n",
      "Loss: 0.0013031057314947248\n",
      "Accuracy: %99.87\n",
      "--------------------------\n",
      "Loss: 0.001284945523366332\n",
      "Accuracy: %99.87\n",
      "--------------------------\n",
      "Loss: 0.0008641569293104112\n",
      "Accuracy: %99.91\n",
      "--------------------------\n",
      "Loss: 0.0009297564392909408\n",
      "Accuracy: %99.91\n",
      "--------------------------\n",
      "Loss: 0.0017275706632062793\n",
      "Accuracy: %99.83\n",
      "--------------------------\n",
      "Loss: 0.0008461348479613662\n",
      "Accuracy: %99.92\n",
      "--------------------------\n",
      "Loss: 0.0007291387300938368\n",
      "Accuracy: %99.93\n",
      "--------------------------\n",
      "Loss: 0.0021142116747796535\n",
      "Accuracy: %99.79\n",
      "--------------------------\n",
      "Loss: 0.002651814604178071\n",
      "Accuracy: %99.73\n",
      "--------------------------\n",
      "Loss: 0.0006644336390309036\n",
      "Accuracy: %99.93\n",
      "--------------------------\n",
      "Loss: 0.0015021197032183409\n",
      "Accuracy: %99.85\n",
      "--------------------------\n",
      "Loss: 0.0002869036397896707\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Loss: 0.002068765228614211\n",
      "Accuracy: %99.79\n",
      "--------------------------\n",
      "Loss: 0.00025866791838780046\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Loss: 0.000848029216285795\n",
      "Accuracy: %99.92\n",
      "--------------------------\n",
      "Loss: 0.0018474124372005463\n",
      "Accuracy: %99.82\n",
      "--------------------------\n",
      "Loss: 0.000811889476608485\n",
      "Accuracy: %99.92\n",
      "--------------------------\n",
      "Loss: 0.0019884391222149134\n",
      "Accuracy: %99.80\n",
      "--------------------------\n",
      "Loss: 0.0008924973662942648\n",
      "Accuracy: %99.91\n",
      "--------------------------\n",
      "Loss: 0.0029618965927511454\n",
      "Accuracy: %99.70\n",
      "--------------------------\n",
      "Loss: 0.00023282485199160874\n",
      "Accuracy: %99.98\n",
      "--------------------------\n",
      "Loss: 0.0002831318706739694\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Loss: 0.001670766738243401\n",
      "Accuracy: %99.83\n",
      "--------------------------\n",
      "Loss: 0.002142121084034443\n",
      "Accuracy: %99.79\n",
      "--------------------------\n",
      "Loss: 0.001140243955887854\n",
      "Accuracy: %99.89\n",
      "--------------------------\n",
      "Loss: 0.0008228151127696037\n",
      "Accuracy: %99.92\n",
      "--------------------------\n",
      "Loss: 0.000283723056782037\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Loss: 0.0005126569303683937\n",
      "Accuracy: %99.95\n",
      "--------------------------\n",
      "Loss: 0.0007446965901181102\n",
      "Accuracy: %99.93\n",
      "--------------------------\n",
      "Loss: 0.0005707028321921825\n",
      "Accuracy: %99.94\n",
      "--------------------------\n",
      "Loss: 0.0006511644460260868\n",
      "Accuracy: %99.93\n",
      "--------------------------\n",
      "Loss: 0.0002779000496957451\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Loss: 0.0008328105323016644\n",
      "Accuracy: %99.92\n",
      "--------------------------\n",
      "Loss: 0.0002566568145994097\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Loss: 0.00015367777086794376\n",
      "Accuracy: %99.98\n",
      "--------------------------\n",
      "Loss: 0.00012802272976841778\n",
      "Accuracy: %99.99\n",
      "--------------------------\n",
      "Loss: 0.00026916558272205293\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Loss: 0.000807737116701901\n",
      "Accuracy: %99.92\n",
      "--------------------------\n",
      "Loss: 0.001039923052303493\n",
      "Accuracy: %99.90\n",
      "--------------------------\n",
      "Loss: 0.0010490801651030779\n",
      "Accuracy: %99.90\n",
      "--------------------------\n",
      "Loss: 0.0015952101675793529\n",
      "Accuracy: %99.84\n",
      "--------------------------\n",
      "Loss: 0.00022871876717545092\n",
      "Accuracy: %99.98\n",
      "--------------------------\n",
      "Loss: 0.002528415061533451\n",
      "Accuracy: %99.75\n",
      "--------------------------\n",
      "Loss: 0.0009905066108331084\n",
      "Accuracy: %99.90\n",
      "--------------------------\n",
      "Loss: 0.00016592133033555\n",
      "Accuracy: %99.98\n",
      "--------------------------\n",
      "Loss: 0.0002041299012489617\n",
      "Accuracy: %99.98\n",
      "--------------------------\n",
      "Loss: 0.00024226673122029752\n",
      "Accuracy: %99.98\n",
      "--------------------------\n",
      "Loss: 0.0014062271220609546\n",
      "Accuracy: %99.86\n",
      "--------------------------\n",
      "Loss: 0.000394692673580721\n",
      "Accuracy: %99.96\n",
      "--------------------------\n",
      "Loss: 0.0008575115934945643\n",
      "Accuracy: %99.91\n",
      "--------------------------\n",
      "Loss: 0.0007332814275287092\n",
      "Accuracy: %99.93\n",
      "--------------------------\n",
      "Loss: 0.001966092037037015\n",
      "Accuracy: %99.80\n",
      "--------------------------\n",
      "Loss: 0.001552240690216422\n",
      "Accuracy: %99.84\n",
      "--------------------------\n",
      "Loss: 0.000303310138406232\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Loss: 0.0007159432279877365\n",
      "Accuracy: %99.93\n",
      "--------------------------\n",
      "Loss: 0.00047129232552833855\n",
      "Accuracy: %99.95\n",
      "--------------------------\n",
      "Loss: 0.0011354375164955854\n",
      "Accuracy: %99.89\n",
      "--------------------------\n",
      "Loss: 0.0015098208095878363\n",
      "Accuracy: %99.85\n",
      "--------------------------\n",
      "Loss: 0.00026489311130717397\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Loss: 0.0003596506721805781\n",
      "Accuracy: %99.96\n",
      "--------------------------\n",
      "Loss: 0.00040953984716907144\n",
      "Accuracy: %99.96\n",
      "--------------------------\n",
      "Loss: 0.00026453056489117444\n",
      "Accuracy: %99.97\n",
      "--------------------------\n",
      "Reward[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "First episode where the reward equals 1 is the 28th episode.\n",
      "Training size is 1000 and the reward could be reached in 25 of them.\n",
      "The training is 25 / 1000 succesful.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.animation as animation\n",
    "from statistics import variance\n",
    "from PIL import Image\n",
    "import os\n",
    "import imageio\n",
    "import wandb\n",
    "\n",
    "class DeepQLearningNetwork(nn.Module):\n",
    "    def __init__(self, input_state, hidden_layer, output_state):\n",
    "        super().__init__()\n",
    "        self.first_layer = nn.Linear(input_state, hidden_layer)  \n",
    "        self.last_layer = nn.Linear(hidden_layer, output_state) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.first_layer(x))\n",
    "        x = self.last_layer(x)        \n",
    "        return x\n",
    "\n",
    "class ReplayMemory():\n",
    "    def __init__(self, maxlen):\n",
    "        self.memory = deque([], maxlen=maxlen)\n",
    "    \n",
    "    def append(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        return random.sample(self.memory, sample_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class DeepQLearning():\n",
    "    BATCH_SIZE = 32 \n",
    "    BUFFER_SIZE = 1000 \n",
    "    LR = 0.001\n",
    "    DISCOUNT = 0.9    \n",
    "    SYNC_STEPS = 10 \n",
    "    loss_function = nn.MSELoss() \n",
    "    optimizer = None\n",
    "    actions = [\"Left\", \"Down\", \"Right\", \"Up\"]\n",
    "\n",
    "    wandb.init(project=\"frozen_lake_project\", config={\"BATCH_SIZE\": BATCH_SIZE, \"LR\": LR, \"DISCOUNT\": DISCOUNT, \n",
    "                                                    \"SYNC_STEPS\": SYNC_STEPS})\n",
    "\n",
    "    def train(self, episodes, is_slippery=False):\n",
    "        \n",
    "        env = gym.make(\"FrozenLake-v1\", map_name=\"4x4\", is_slippery=is_slippery, render_mode=\"human\")\n",
    "        number_of_states = env.observation_space.n\n",
    "        number_of_actions = env.action_space.n\n",
    "        \n",
    "        EPS = 1 \n",
    "        memory = ReplayMemory(self.BUFFER_SIZE)\n",
    "\n",
    "        policy_dqn = DeepQLearningNetwork(number_of_states, number_of_states, number_of_actions)\n",
    "        target_dqn = DeepQLearningNetwork(number_of_states, number_of_states, number_of_actions)\n",
    "\n",
    "        target_dqn.load_state_dict(policy_dqn.state_dict())\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(policy_dqn.parameters(), lr=self.LR)\n",
    "\n",
    "        global rewards_per_episode\n",
    "        rewards_per_episode = np.zeros(episodes)\n",
    "\n",
    "        epsilon_history = []\n",
    "\n",
    "        step_count=0\n",
    "            \n",
    "        for i in range(episodes):\n",
    "            state = env.reset()[0]\n",
    "            terminated = False     \n",
    "            truncated = False    \n",
    "\n",
    "            while(not terminated and not truncated):\n",
    "\n",
    "                if random.random() < EPS:\n",
    "                    action = env.action_space.sample() \n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        action = policy_dqn(self.state_to_tensor_represantation(state, number_of_states)).argmax().item()\n",
    "\n",
    "                new_state, reward, terminated, truncated, _ = env.step(action)\n",
    "                memory.append((state, action, new_state, reward, terminated))\n",
    "                state = new_state\n",
    "                step_count += 1\n",
    "\n",
    "            if reward == 1:\n",
    "                rewards_per_episode[i] = 1\n",
    "\n",
    "            if len(memory) > self.BATCH_SIZE and np.sum(rewards_per_episode) > 0:\n",
    "                mini_batch = memory.sample(self.BATCH_SIZE)\n",
    "                self.optimize(mini_batch, policy_dqn, target_dqn)   \n",
    "\n",
    "                EPS = max(EPS - 1 / episodes, 0)\n",
    "                epsilon_history.append(EPS)\n",
    "\n",
    "                if step_count > self.SYNC_STEPS:\n",
    "                    target_dqn.load_state_dict(policy_dqn.state_dict())\n",
    "                    step_count = 0\n",
    "\n",
    "        env.close()\n",
    "\n",
    "        torch.save(policy_dqn.state_dict(), \"best_model.pt\")\n",
    "        print(f\"Reward{rewards_per_episode}\")\n",
    "\n",
    "        try:\n",
    "            reward_is_1 = rewards_per_episode.tolist().index(1)\n",
    "            print(f\"First episode where the reward equals 1 is the {reward_is_1 + 1}th episode.\")\n",
    "\n",
    "            total_reward_is_1 = [reward for reward, x in enumerate(rewards_per_episode) if x == 1]\n",
    "            print(f\"Training size is {train_episode_count} and the reward could be reached in {len(total_reward_is_1)} of them.\")\n",
    "\n",
    "            print(f\"The training is {len(total_reward_is_1)} / {train_episode_count} succesful.\")\n",
    "            \n",
    "            plt.figure(dpi=200, figsize=(6, 4))\n",
    "            plt.title(\"Reward Per Episode\")\n",
    "            plt.xlabel(\"Episode\")\n",
    "            plt.ylabel(\"Reward\")\n",
    "            plt.boxplot(rewards_per_episode)\n",
    "            \n",
    "\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        sum_rewards = np.zeros(episodes)\n",
    "\n",
    "        \n",
    "    def optimize(self, mini_batch, policy_dqn, target_dqn):\n",
    "\n",
    "        number_of_states = policy_dqn.first_layer.in_features\n",
    "\n",
    "        current_q_list = []\n",
    "        target_q_list = []\n",
    "\n",
    "        for state, action, new_state, reward, terminated in mini_batch:\n",
    "\n",
    "            if terminated: \n",
    "                target = torch.FloatTensor([reward])\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    target = torch.FloatTensor(\n",
    "                        reward + self.DISCOUNT * target_dqn(self.state_to_tensor_represantation(new_state, number_of_states)).max())\n",
    "\n",
    "            current_q = policy_dqn(self.state_to_tensor_represantation(state, number_of_states))\n",
    "            current_q_list.append(current_q)\n",
    "\n",
    "            target_q = target_dqn(self.state_to_tensor_represantation(state, number_of_states)) \n",
    "            target_q[action] = target\n",
    "            target_q_list.append(target_q)\n",
    "\n",
    "        loss = self.loss_function(torch.stack(current_q_list), torch.stack(target_q_list))\n",
    "        \n",
    "        global accuracy\n",
    "        accuracy = (1-loss) * 100\n",
    "\n",
    "        print(f\"Loss: {loss}\")\n",
    "        print(f\"Accuracy: %{accuracy:.2f}\")\n",
    "        print(\"--------------------------\")        \n",
    "\n",
    "        wandb.log({\"Loss\": loss, \"Accuracy\": accuracy, \"Reward\": rewards_per_episode})\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "    def state_to_tensor_represantation(self, state:int, number_of_states:int):\n",
    "        input_tensor = torch.zeros(number_of_states)\n",
    "        input_tensor[state] = 1\n",
    "        return input_tensor\n",
    "\n",
    "    def test(self, episodes, is_slippery=False):\n",
    "        \n",
    "        env = gym.make(\"FrozenLake-v1\", map_name=\"4x4\", is_slippery=is_slippery, render_mode=\"rgb_array\")\n",
    "        number_of_states = env.observation_space.n\n",
    "        number_of_actions = env.action_space.n\n",
    "\n",
    "        policy_dqn = DeepQLearningNetwork(number_of_states, number_of_states, number_of_actions) \n",
    "        policy_dqn.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "        policy_dqn.eval()  \n",
    "\n",
    "        for i in range(episodes):\n",
    "            state = env.reset()[0]  \n",
    "            terminated = False    \n",
    "            truncated = False                \n",
    "\n",
    "            while(not terminated and not truncated):  \n",
    "                with torch.no_grad():\n",
    "                    action = policy_dqn(self.state_to_tensor_represantation(state, number_of_states)).argmax().item()\n",
    "\n",
    "                state, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        env.close()\n",
    "\n",
    "    def box_whisker_plot(self, var):\n",
    "        plt.figure(figsize=(8, 4), dpi=150)\n",
    "        plt.xlabel(\"X Label\")\n",
    "        plt.ylabel(\"Mean Accuracy\")\n",
    "        plt.boxplot(x=var.detach().numpy().reshape(1), widths=0.6, showmeans=True)\n",
    "        plt.show()\n",
    "        plt.savefig(\"graphs/box_whiskers_plot_accuracy.png\")\n",
    "\n",
    "\n",
    "model = DeepQLearning()\n",
    "train_episode_count = 1000\n",
    "test_episode_count = 10\n",
    "\n",
    "model.train(train_episode_count, is_slippery=False)\n",
    "model.test(test_episode_count, is_slippery=False)\n",
    "model.box_whisker_plot(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
